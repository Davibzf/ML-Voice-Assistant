# ğŸ§  ML Voice Assistant â€“ V1

**Assistente de voz pessoal desenvolvido em Python com pipeline completo de IA:**

**captura de Ã¡udio â†’ transcriÃ§Ã£o â†’ processamento com LLM â†’ resposta por sÃ­ntese de voz**

---

## ğŸ“‹ Ãndice
- [Sobre o Projeto](#-sobre-o-projeto)
- [Pipeline do Sistema](#-pipeline-do-sistema)
- [Tecnologias](#-tecnologias)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Como Executar](#-como-executar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Exemplo de Uso](#-exemplo-de-uso)
- [LimitaÃ§Ãµes Atuais](#-limitaÃ§Ãµes-atuais-v1)
- [Roadmap](#-prÃ³ximas-melhorias-roadmap)
- [Desafios TÃ©cnicos](#-desafios-tÃ©cnicos-enfrentados)
- [Autor](#-autor)

---

## ğŸ¯ Sobre o Projeto

Este assistente de voz Ã© capaz de:
- ğŸ¤ **Ouvir** comandos do usuÃ¡rio via microfone
- ğŸ“ **Transcrever** Ã¡udio para texto com Whisper
- ğŸ§  **Processar** o conteÃºdo com Google Gemini API
- ğŸ”Š **Responder** verbalmente atravÃ©s de sÃ­ntese de voz

> âš ï¸ **Status:** VersÃ£o 1 â€“ Uso pessoal e aprendizado

---

## ğŸ”„ Pipeline do Sistema

```
ğŸ¤ Entrada de Ãudio
    â†“
ğŸ“ Speech-to-Text (Whisper)
    â†“
ğŸ§  Processamento (Gemini API)
    â†“
ğŸ”Š Text-to-Speech (pyttsx3)
    â†“
ğŸ—£ï¸ Resposta em Ãudio
```

---

## ğŸ› ï¸ Tecnologias

| Categoria | Tecnologia | FunÃ§Ã£o |
|-----------|------------|--------|
| **Linguagem** | Python 3.11+ | Base do projeto |
| **STT** | Whisper (OpenAI) | TranscriÃ§Ã£o Ã¡udio â†’ texto (modelo 'tiny') |
| **LLM** | Google Gemini API | Processamento de linguagem natural |
| **Ãudio** | PyAudio + Wave | Captura e manipulaÃ§Ã£o de Ã¡udio |
| **TTS** | pyttsx3 | SÃ­ntese de voz offline |
| **ConcorrÃªncia** | Threading | Controle da gravaÃ§Ã£o |

---

## âš™ï¸ PrÃ©-requisitos

### DependÃªncias de Sistema
- **FFmpeg** (necessÃ¡rio para Whisper)
- **PortAudio** (para PyAudio)

### DependÃªncias Python
```bash
pyaudio
wave
whisper
google-generativeai
pyttsx3
```

---

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/ml-voice-assistant.git

# Entre no diretÃ³rio
cd ml-voice-assistant

# Instale as dependÃªncias
pip install -r requirements.txt
```

### ğŸ”‘ ConfiguraÃ§Ã£o da API Key

1. Acesse [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Gere sua chave da API Gemini
3. Adicione no cÃ³digo:

```python
genai.configure(api_key="sua_chave_aqui")
```

---

## ğŸš€ Como Executar

Execute as cÃ©lulas do notebook sequencialmente:

| Etapa | AÃ§Ã£o |
|-------|------|
| **1** | Pressione ENTER para comeÃ§ar a gravar |
| **2** | Fale seu comando |
| **3** | Pressione ENTER para parar a gravaÃ§Ã£o |
| **4** | Aguarde o processamento automÃ¡tico |
| **5** | OuÃ§a a resposta do assistente |

---

## ğŸ“Š Estrutura do Projeto

O notebook `ML-VA.ipynb` contÃ©m 4 cÃ©lulas principais:

```python
# 1. GRAVAÃ‡ÃƒO
- Captura Ã¡udio do microfone
- Salva como 'gravacao.wav'

# 2. SPEECH-TO-TEXT
- Carrega modelo Whisper 'tiny'
- Transcreve Ã¡udio para texto
- Salva transcriÃ§Ã£o em 'transcricao.txt'

# 3. LLM (GEMINI)
- LÃª arquivo de transcriÃ§Ã£o
- Envia para API Gemini
- Retorna resposta processada

# 4. TEXT-TO-SPEECH
- Converte resposta em Ã¡udio
- Reproduz via auto-falante
```

---

## ğŸ’¡ Exemplo de Uso

**UsuÃ¡rio:** "Quais sÃ£o as linguagens de programaÃ§Ã£o mais utilizadas no mercado atualmente?"

**Processamento:**
```python
# Whisper transcreve o Ã¡udio
texto_usuario = "quais sÃ£o as linguagens de programaÃ§Ã£o mais utilizadas no mercado atualmente"

# Gemini processa e responde
resposta_ia = "Python, JavaScript, Java e C# estÃ£o entre as mais utilizadas..."

# pyttsx3 reproduz em voz
engine.say(resposta_ia)
```

**Assistente:** *(responde em Ã¡udio com as informaÃ§Ãµes)*

---

## âš ï¸ LimitaÃ§Ãµes Atuais (V1)

| LimitaÃ§Ã£o | DescriÃ§Ã£o |
|-----------|-----------|
| âŒ **ExecuÃ§Ã£o Ãºnica** | NÃ£o opera em loop contÃ­nuo |
| âŒ **Sem wake word** | Precisa de interaÃ§Ã£o manual |
| âŒ **DependÃªncia de internet** | API Gemini requer conexÃ£o |
| âŒ **Processamento sÃ­ncrono** | Bloqueante durante execuÃ§Ã£o |
| âŒ **Sem tratamento de erros** | Falhas nÃ£o sÃ£o capturadas |

---

## ğŸ”® PrÃ³ximas Melhorias (Roadmap)

### ğŸŸ¢ V2 â€“ Melhorias Imediatas
- [ ] Loop contÃ­nuo de execuÃ§Ã£o
- [ ] Tratamento de exceÃ§Ãµes
- [ ] Sistema de logs
- [ ] ConfiguraÃ§Ãµes externalizadas

### ğŸŸ¡ V3 â€“ Funcionalidades AvanÃ§adas
- [ ] Wake word detection ("Hey Assistente")
- [ ] Comandos especÃ­ficos (abrir programas, clima)
- [ ] Fallback para modelo local (offline)
- [ ] Suporte a mÃºltiplos idiomas

### ğŸ”´ V4 â€“ Arquitetura Profissional
- [ ] ContainerizaÃ§Ã£o com Docker
- [ ] API REST com FastAPI
- [ ] Interface web em tempo real
- [ ] Banco de dados para histÃ³rico

---

## ğŸ§ª Desafios TÃ©cnicos Enfrentados

### 1. **ConcorrÃªncia na GravaÃ§Ã£o**
```python
# SoluÃ§Ã£o: Thread paralela para capturar ENTER durante gravaÃ§Ã£o
threading.Thread(target=wait_stop).start()
```

### 2. **PreparaÃ§Ã£o do Texto para TTS**
```python
# Limpeza de caracteres especiais com regex
au = re.sub(r'[^a-zA-Z0-9]', '', resp)
```

### 3. **Performance do Whisper**
- Escolha do modelo 'tiny' (mais leve) para execuÃ§Ã£o local rÃ¡pida
- Taxa de amostragem configurada para 16000 Hz (otimizada para fala)

### 4. **IntegraÃ§Ã£o Jupyter**
- AdaptaÃ§Ã£o do fluxo para execuÃ§Ã£o em cÃ©lulas
- Controle manual via `input()` para gravaÃ§Ã£o

---

## ğŸ‘¨â€ğŸ’» Autor

**Davi Bezerra Fraga**  
Estudante de desenvolvimento backend e InteligÃªncia Artificial

- ğŸ”— [LinkedIn](https://www.linkedin.com/in/davi-bezerra-fraga-319a49363/)
- ğŸ™ [GitHub](https://github.com/Davibzf)
- ğŸ“§ [Email](mailto:davibezerrafraga@gmail.com)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

> â­ **Se este projeto te ajudou de alguma forma, considere dar uma estrela no GitHub!**  
> ğŸ’¬ *Feedback e contribuiÃ§Ãµes sÃ£o sempre bem-vindos*

---

## ğŸ“Œ Notas TÃ©cnicas Importantes

```python
# ConfiguraÃ§Ãµes utilizadas
RATE = 16000  # Hz (otimizado para reconhecimento de fala)
CHUNK = 10000  # Tamanho do buffer
FORMAT = pyaudio.paInt16  # Formato de Ã¡udio
CHANNELS = 1  # Mono (ideal para voz)
```

**ObservaÃ§Ãµes:**
- O modelo Whisper 'tiny' foi escolhido por equilÃ­brio entre precisÃ£o e performance local
- pyttsx3 opera totalmente offline, sem dependÃªncia de nuvem
- Taxa de 16000 Hz Ã© padrÃ£o para sistemas de reconhecimento de fala
